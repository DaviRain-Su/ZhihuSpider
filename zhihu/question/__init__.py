import os
import re
import logging
from json.decoder import JSONDecodeError

from bs4 import BeautifulSoup

import zhihu
from util import const
from util import document
from util import net
from util.timer import timer

logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s %(message)s')

__all__ = ['answer', 'answers', 'make_answers_as_book']

template = '''
{} {}    {} / {}  ğŸ‘ {}
    {}
    è¯„åˆ†ï¼š{:<.2f}
    æ”¶å½•ï¼š{}
'''


def answer(answer_id, warehouse):
    response = net.answer_spider(answer_id)
    if response is not None:
        answer_content = response.json()
        content = BeautifulSoup(answer_content['content'], 'lxml').body
        # # TODO DEBUG TAG CLEAR AFTER FINISH!
        # with open(answer_id + '.html', 'w', encoding='utf8') as foo:
        #     foo.write(content.prettify())
        msg = answer_msg(answer_content)
        an = document.Answer(content, msg)
        an.make_markdown(warehouse)
        return an.answer_msg()
    else:
        raise ValueError('Response is None')


def answers(question_id, warehouse):
    offset = zhihu.Controller(collect_all=True)
    warehouse = question_warehouse(question_id, warehouse)
    logger.info("å¼€å§‹æŠ“å–é—®é¢˜ %s çš„å›ç­”ï¼Œè¾“å‡ºç›®å½•ï¼š%s", question_id, warehouse)
    while not offset.is_end():
        response = fetch_answers_page(question_id, offset.next_offset())
        try:
            response_json = response.json()
            offset.totals = response_json['paging']['totals']
            database: list = response_json['data']
            offset.increase(len(database))
            logger.info("æ‰¹æ¬¡ offset=%dï¼Œè·å– %d æ¡ï¼Œç›®æ ‡æ€»æ•°=%s", offset.next_offset(), len(database), offset.totals)
            for answer_content in database:
                msg = answer_msg(answer_content)
                if not offset.to_collect(answer_content):
                    continue
                content = parse_answer_body(answer_content)
                if content is None:
                    logger.warning("å›ç­”å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æï¼Œquestion=%s, answer=%sï¼Œå·²è·³è¿‡",
                                   question_id, answer_content.get('id'))
                    continue
                an = document.Answer(content, msg)
                an.set_file_name(template='%a-%v')
                an.make_markdown(warehouse)
                print(an.answer_msg())
            timer.sleep_for(zhihu.SLEEP)
        except JSONDecodeError as e:
            debug_response(response)
            raise e


def answer_msg(answer_content):
    author = answer_content['author']['name']
    voteup = answer_content['voteup_count']
    title = answer_content['question']['title']
    question_id = answer_content['question']['id']
    answer_id = answer_content['id']
    original_url = const.ANSWER_URL.format(question_id, answer_id)
    author_page = const.AUTHOR_PAGE_URL.format(answer_content['author']['url_token'])
    avatar = answer_content['author']['avatar_url_template'].replace(const.AVATAR_SIZE_R,
                                                                     const.AVATAR_SIZE_A)
    date = timer.timestamp_to_date(answer_content['created_time'])
    answer_dict = {'author': author, 'author_avatar_url': avatar, 'author_page': author_page, 'title': title,
                   'original_url': original_url, 'created_date': date, 'voteup': voteup}
    return document.Meta(**answer_dict)


def question_warehouse(question_id, warehouse):
    response = net.question_msg_spider(question_id)
    if response is not None:
        response_json = response.json()
        name = response_json['title']
        name = re.sub(r'[\\/]', 'ã€', name)
        name = re.sub(r'[ï¼Ÿ?*:<>|]', '', name)
        warehouse = os.path.join(warehouse, name)
        if not os.path.exists(warehouse):
            os.makedirs(warehouse)
            logger.info("åˆ›å»ºè¾“å‡ºç›®å½•ï¼š%s", warehouse)
        return warehouse
    else:
        raise ValueError('Response is None')


def make_answers_as_book(question_id, warehouse):
    offset = zhihu.Controller(collect_all=True)
    response = net.question_msg_spider(question_id)
    if response is not None:
        response_json = response.json()
        name = response_json['title']
        name = re.sub(r'[\\/]', 'ã€', name)
        title = re.sub(r'[ï¼Ÿ?*:<>|]', '', name)
    else:
        raise ValueError('Response is None')
    book_path = os.path.join(warehouse, title + '.md')
    logger.info("å¼€å§‹æŠ“å–é—®é¢˜ %sï¼Œç”Ÿæˆåˆé›†ï¼š%s", question_id, book_path)
    book = open(book_path, 'a', encoding='utf8')
    while not offset.is_end():
        response = fetch_answers_page(question_id, offset.next_offset())
        try:
            response_json = response.json()
            offset.totals = response_json['paging']['totals']
            database: list = response_json['data']
            offset.increase(len(database))
            logger.info("æ‰¹æ¬¡ offset=%dï¼Œè·å– %d æ¡ï¼Œç›®æ ‡æ€»æ•°=%s", offset.next_offset(), len(database), offset.totals)
            for answer_content in database:
                msg = answer_msg(answer_content)
                if not offset.to_collect(answer_content):
                    continue
                content = parse_answer_body(answer_content)
                if content is None:
                    logger.warning("å›ç­”å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æï¼Œquestion=%s, answer=%sï¼Œå·²è·³è¿‡", question_id,
                                   answer_content.get('id'))
                    continue
                an = document.Answer(content, msg)
                an.set_file_name(template='%a-%v')
                book.write(an.to_markdown())
                book.write('\n---\n')
                print(an.answer_msg())
            timer.sleep_for(zhihu.SLEEP)
        except JSONDecodeError as e:
            debug_response(response)
            book.close()
            logger.error("è§£æå¤±è´¥ï¼Œå·²ä¿ç•™å½“å‰æ–‡ä»¶ï¼š%sï¼Œé”™è¯¯ï¼š%s", book_path, e)
            raise e
    book.close()
    logger.info("é—®é¢˜ %s æŠ“å–å®Œæˆï¼Œæ–‡ä»¶å·²å†™å…¥ï¼š%s", question_id, book_path)


def debug_response(response):
    """æ‰“å°æ¥å£è°ƒè¯•ä¿¡æ¯ï¼Œè¾…åŠ©å®šä½ 403/é JSON å“åº”"""
    if response is None:
        print('response is None')
        return
    print('debug status/url:', getattr(response, 'status_code', '?'), getattr(response, 'url', '?'))
    try:
        print('debug headers snippet:', {k: response.headers.get(k) for k in ['content-type', 'content-encoding', 'x-req-id', 'x-api-version']})
    except Exception:
        pass
    try:
        text = response.text
        print('debug body snippet:', text[:400])
    except Exception as err:
        print('debug body read error:', err)


def ensure_response_ok(response, question_id, offset):
    """ç¡®ä¿å“åº”æœ‰æ•ˆï¼Œä¾¿äºå®šä½ 403/401/ç©ºå“åº”"""
    if response is None:
        msg = f"question={question_id}, offset={offset}: response is Noneï¼Œå¯èƒ½è¢«é™æµæˆ–é‰´æƒå¤±æ•ˆ"
        logger.error(msg)
        raise RuntimeError(msg)
    status = getattr(response, 'status_code', 200)
    if status != 200:
        debug_response(response)
        msg = f"question={question_id}, offset={offset}: status {status}ï¼Œè¯·æ›´æ–°è¯·æ±‚å¤´æˆ–æ”¾æ…¢é¢‘ç‡"
        logger.error(msg)
        raise RuntimeError(msg)


def fetch_answers_page(question_id, offset):
    """æºå¸¦é‡è¯•çš„å›ç­”åˆ—è¡¨è¯·æ±‚ï¼Œé™ä½ 403/429 é€ æˆçš„ä¸­æ–­"""
    last_resp = None
    for attempt in range(1, 4):
        resp = net.answers_spider(question_id, offset, const.SORT_BY_VOT)
        last_resp = resp
        if resp is None:
            wait = zhihu.SLEEP * attempt
            logger.warning("å°è¯• %d/3: question=%s offset=%d å“åº” Noneï¼Œç­‰å¾… %ss é‡è¯•", attempt, question_id, offset, wait)
            timer.sleep_for(wait)
            continue
        status = getattr(resp, 'status_code', 200)
        if status != 200:
            wait = zhihu.SLEEP * attempt
            logger.warning("å°è¯• %d/3: question=%s offset=%d çŠ¶æ€ %sï¼Œç­‰å¾… %ss é‡è¯•", attempt, question_id, offset, status, wait)
            debug_response(resp)
            timer.sleep_for(wait)
            continue
        return resp
    # é‡è¯•åä»å¤±è´¥ï¼ŒæŠ›å‡ºè¯¦ç»†é”™è¯¯
    ensure_response_ok(last_resp, question_id, offset)
    return last_resp


def parse_answer_body(answer_content):
    """è§£æå›ç­”ä¸»ä½“çš„ HTMLï¼Œè‹¥æ—  body åˆ™è¿”å› None"""
    content_html = answer_content.get('content') if isinstance(answer_content, dict) else None
    if not content_html:
        return None
    soup = BeautifulSoup(content_html, 'lxml')
    return soup.body


"""
è¯´æ˜ï¼š
    è¿™é‡Œå®ç°äº†å¯¹å•ä¸ªå›ç­”æˆ–é—®é¢˜çš„æ‰€æœ‰å›ç­”çš„çˆ¬å–ï¼Œå…¶ä¸­å•ä¸ªå›ç­”çš„çˆ¬å–éœ€è¦çš„æ˜¯answer_idï¼Œè€Œé—®é¢˜çš„æ‰€æœ‰å›ç­”éœ€è¦çš„æ˜¯
question_idã€‚é€šè¿‡ç›¸åº”çš„idå‘èµ·ç½‘ç»œè¯·æ±‚ï¼Œè¿”å›çš„jsonæ–‡ä»¶ä¸­åŒ…å«çš„å†…å®¹çš„ä¸»ä½“ï¼Œé€šè¿‡è§£æjsonæ–‡ä»¶è·å¾—æ–‡ç« çš„åŸºæœ¬ä¿¡æ¯ï¼Œç”Ÿ
æˆä¸€ä¸ªmsgå¯¹è±¡ï¼Œå†å°†å†…å®¹ä¸»ä½“è§£ææˆBeautifulSoupå¯¹è±¡ï¼Œè¿åŒmsgä¸€èµ·äº¤ç»™documentä¸‹çš„æœ‰å…³ç±»è§£æç”Ÿæˆmarkdownæ–‡ä»¶
"""
